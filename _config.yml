# Site
# repository: sproogen/resume-theme
repository: sulabhkatiyar.github.io
favicon: images/favicon.ico

# Content configuration version
version: 2

# Personal info
name: Sulabh Katiyar
title: Research Student pursuing Ph.D 
email: sulabhkatiyar@gmail.com
website: sulabhkatiyar.github.io

# Dark Mode (true/false/never)
darkmode: false

# Social links
# twitter_username: 
github_username:  sulabhkatiyar
# stackoverflow_username: "00000001"
# dribbble_username: jekyll
# facebook_username: jekyll
# flickr_username: jekyll
# instagram_username: jameswgrant
linkedin_username: sulabhkatiyar
# xing_username: jekyll
# pinterest_username: jekyll
# youtube_username: globalmtb
# googleplus_username: +jekyll
# orcid_username: 0000-0000-0000-0000

# Additional icon links
# additional_links:
# - title: itsgoingto.be
#   icon: fas fa-globe
#   url: https://www.itsgoingto.be
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
about_title: About Me
# about_profile_image: images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  Hi, my name is Sulabh Katiyar and I am a research student working towards my Ph.D on Image Caption Generation. During my Ph.D I have studied Encoder-Decoder and
  Attention based frameworks and focussed on better utilization of Visual and Semantic Information in Caption Generation process.
  
  My Research Interests lie in Computer Vision and Natural Language Processing tasks such as Machine Translation, Image Captioning, Text Summarization, etc.

#  I am most skilled in: <mark>Python programming language</mark> and <mark>Eating Pizza</mark>

content:
  - title: Education # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Ph.D 
        caption: 2015 - 2021
        sub_title: National Institute of Technology, Silchar
        # quote: >
        #   Established in 1636, Harvard is the oldest higher education institution in the United States, and is widely regarded in terms of its influence, reputation, and academic pedigree as a leading university in not just the US but also the world.
        description: | # this will include new lines to allow paragraphs
          I have studied Image Caption Generation during my Ph.D with a focus on eficient utilization of semantic and visual information 
          for Caption Generation. I have performed comparative analysis of methods proposed in previous works and proposed methods to address
          their limitations. Some of the works towards perusal of my Ph.D are listed below. This includes only published/accepted works.
          - To analyse role of image representation obtained from various pre-trained Convolutional Neural Networks (CNN), I performed comparative
          analysis of different CNN architectures to study their efficacy for Image Caption Generation task. 
          - I have performed comparative analysis of Recurrent Neural Network based Decoder with the recently proposed Convolutional Decoder. 
          I have observed that Convolutional Decoder does not model long term word relationships efficiently.
          - I have proposed Encoder-Decoder and Visual Attention based Caption Generation methods using Contextual Word Embedding Representations for
          enhanced semantic information representation and Perspective Transforms as Data Augmentation mechanism for better exploitation of Visual information.
          In addition, I have used fine tuning of both CNN and Word embedding layers to obtain performance improvements.
          
          The tentative date of my thesis submission is 17th September, 2021.

      - layout: left
        title: M.Tech
        caption: 2013 - 2015
        sub_title: National Institute of Technology, Silchar
        # quote: >
        #   Established in 1636, Harvard is the oldest higher education institution in the United States, and is widely regarded in terms of its influence, reputation, and academic pedigree as a leading university in not just the US but also the world.
        description: | # this will include new lines to allow paragraphs
          I have worked on Extractive Text Summarization during my M.Tech study. I have used lexical relationships among words to formulate improved method for 
          identification of sentences from the text which can be used as summary.
          
      - layout: left
        title: B.Tech
        caption: 2009 - 2013
        sub_title: National Institute of Technology, Silchar
        # quote: >
        #   Established in 1636, Harvard is the oldest higher education institution in the United States, and is widely regarded in terms of its influence, reputation, and academic pedigree as a leading university in not just the US but also the world.
        description: | # this will include new lines to allow paragraphs
          During my time at NIT Silchar I learnt the basics of Computer Science and Engineering which have served as foundation over which I have continued my studies during M.Tech
          and Ph.D. I also learned skills such as teamwork and working to tight deadlines. I thouroughly enjoyed my time during B.Tech and learnt a lot which has helped me later in life.
          I spent my free time participating in Quiz Competitions. I also organized a Quiz Competition during annual College Fest. In addition, I served as committee member in 
          organizing teams of annual Alumni Meet and some technical competititions organized by Computer Science and Engineering Department
          
  - title: Projects # Title for the section
    layout: list # Type of content section (list/text)
    quote: >
       This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
    content:
      - layout: left # top-middle
        title: Encoder-Decoder
        # link: github.com/sulabhkatiyar/show_tell
        # link_text: Project Website
        additional_links:
          - title: Encoder-Decoder
            icon: fab fa-github
            url: github.com/sulabhkatiyar/show_tell
          # - title:  Github page for project (eg. sproogen/modern-resume-theme)
          #   icon: fab fa-github
          #   url: Link to project (eg. sproogen.github.io/modern-resume-theme)
        # quote: >
        #   This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          I have implemented [Encoder-Decoder](github.com/sulabhkatiyar/show_tell) based Image Captioning method. 
          This method is similar to the Google NIC method proposed in the paper _Show and tell: A neural image caption generator_ 
          [[link]](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Vinyals_Show_and_Tell_2015_CVPR_paper.html).
          In this method, an LSTM network is used to generate the next word using word embedding representations of previous words in sentence. Image representation
          generated by a pre-trained CNN is used to initialize hidden and cell states of LSTM. 
          
      - layout: right # top-middle
        title: Spatial and Adaptive Attention
        additional_links:
          - title: Spatial
            icon: fab fa-github
            url: https://github.com/sulabhkatiyar/Spatial_Att
          - title: Adaptive
            icon: fab fa-github
            url: https://github.com/sulabhkatiyar/Adaptive_Att
        # quote: >
        #   This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          In this work, I have implemented [Spatial](https://github.com/sulabhkatiyar/Spatial_Att) and [Adaptive](https://github.com/sulabhkatiyar/Adaptive_Att)
          attention methods proposed in paper _Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning_ 
          [[link]](https://openaccess.thecvf.com/content_cvpr_2017/papers/Lu_Knowing_When_to_CVPR_2017_paper.pdf). In _Spatial Attention_ method, 
          the current hidden state of LSTM decoder is used to compute relevant portions of visual information at each time-step of caption generation. The relevant 
          visual information thus computed is combined with LSTM hidden state to generate next word.
          This is unlike the Visual Attention approach used in other works such as the _Show, Attend and Tell_ paper [[link]](https://proceedings.mlr.press/v37/xuc15.html) where
          the previous hidden state of LSTM is used to compute relevant visual information which is then used as input to LSTM at current time-step.
          In _Adaptive Attention_ method, the model learns when to rely on visual information and when to rely on the language model. This is based on 
          assumption that model does not need to look at visual information to predict "non-visual" words such as “the”, “of”, etc.

      - layout: left # top-middle
        title: Image Captioning with Bi-directional LSTMs
        additional_links:
          - title: Bi-Directional LSTM
            icon: fab fa-github
            url: https://github.com/sulabhkatiyar/Bi-LSTM
          - title: Bidirectional S-LSTM
            icon: fab fa-github
            url: https://github.com/sulabhkatiyar/Bi_S_LSTM
          - title: Bidirectional F-LSTM
            icon: fab fa-github
            url: https://github.com/sulabhkatiyar/Bi_F_LSTM          
        # quote: >
        #   This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs
          In this work, I have implemented three Caption Generation methods: [Bi-LSTM](https://github.com/sulabhkatiyar/Bi-LSTM),
          [Bi-S-LSTM](https://github.com/sulabhkatiyar/Bi_S_LSTM) and [Bi-F-LSTM](https://github.com/sulabhkatiyar/Bi_F_LSTM)
          proposed in the paper _Image Captioning with Deep Bidirectional LSTMs_ [[link]](https://dl.acm.org/doi/abs/10.1145/3115432). 
          In _Bi-LSTM_ method a two layered Bi-directional LSTM network is used in which first layer models language information and second layer jointly models 
          language and text information. In _Bi-S-LSTM_ method, stacked LSTM layers are used in which first two layers model language information and third layer
          jointly models text and visual information. In _Bi-F-LSTM_ method, two Bi-Directional LSTM layers are used with an intermediate fully connected layer.
          In addition, there is a residual connection between first and second Bidirectional LSTM layers which speeds up training. During inference, both forward and
          backward LSTMs are used for Caption Generation and most likely caption from among them is selected at each time-step.

      - layout: right # top-middle
        title: Captioning with Synchronous Cross-Attention
        additional_links:
          - title: Synchronous Cross-Attention
            icon: fab fa-github
            url: https://github.com/sulabhkatiyar/IC_SCA
        # quote: >
        #   This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
        description: | # this will include new lines to allow paragraphs


  - title: A Little More About Me
    layout: text
    content: | # this will include new lines to allow paragraphs
      Alongside my interests in networks and software engineering some of my other interests and hobbies are:
      - Rock climbing
      - Gaming
      - Knitting
      - [Becoming a ninja](https://www.youtube.com/watch?v=vtg4o__aRMg)

      Look at this cool image  
      ![Trees](/modern-resume-theme/images/landscape-trees.jpg "Trees")

# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
remote_theme: sproogen/resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag
